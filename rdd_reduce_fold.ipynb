{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af0a346e-5aa9-4690-80ac-23d3abc8320f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# fold Action:\n",
    "\n",
    "- takes an initial value &  an aggregation function as parameters.\n",
    "- applies the aggregation function to the elements of the RDD, starting with the initial value. aggregation function takes two arguments: the accumulated result and the next element in the RDD.\n",
    "- result of the fold action is the final aggregated value, which has the same type as the initial value.\n",
    "- fold allows you to specify an initial value, which is important because the RDD might be empty, and you need to provide a meaningful starting point for the aggregation.\n",
    "- can be used for both associative and non-associative aggregation functions because it starts with an initial value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5921e39-7291-401a-8036-248532a478f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "# Initialize SparkContext\n",
    "sc = SparkContext(\"local\", \"foldExample\")\n",
    "\n",
    "# Create an RDD\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "\n",
    "# Use fold to calculate the sum with an initial value of 0\n",
    "total_sum = rdd.fold(0, lambda x, y: x + y)\n",
    "\n",
    "# Print the result\n",
    "print(total_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "092422e8-1461-41c2-8136-8752b5b8b316",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# reduce Action:\n",
    "\n",
    "- takes an aggregation function as its parameter but does not require an initial value. \n",
    "- uses the first element of the RDD as the initial value for the aggregation.\n",
    "- applies the aggregation function to the elements of the RDD, starting with the first element. The aggregation function takes two arguments: the accumulated result and the next element in the RDD.\n",
    "- result of the reduce action is the final aggregated value, which has the same type as the elements in the RDD.\n",
    "- suitable for associative aggregation functions because it relies on the first element of the RDD as the initial value. If the RDD is empty, it will throw an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27bf87ab-0938-40a0-97ed-7cd4fbd7de52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkContext\n",
    "\n",
    "# Initialize SparkContext\n",
    "sc = SparkContext(\"local\", \"reduceExample\")\n",
    "\n",
    "# Create an RDD\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "\n",
    "# Use reduce to calculate the sum\n",
    "total_sum = rdd.reduce(lambda x, y: x + y)\n",
    "\n",
    "# Print the result\n",
    "print(total_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6366fde-22bb-4e11-9af6-883991a5eb84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Differences between fold and reduce:\n",
    "\n",
    "**Initial Value:** \n",
    "- fold requires you to provide an initial value\n",
    "- reduce uses the first element of the RDD as the initial value.\n",
    "\n",
    "**Handling Empty RDDs:** \n",
    "- fold can handle empty RDDs by using the provided initial value\n",
    "- reduce would throw an error if the RDD is empty because it relies on the first element.\n",
    "\n",
    "**Return Type:** \n",
    "- return type of fold is the same as the initial value\n",
    "- return type of reduce is the same as the elements in the RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7579367a-d086-497f-8c17-f56803054da4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "rdd_reduce_fold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
