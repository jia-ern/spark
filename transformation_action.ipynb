{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e789156d-6c87-4e5d-ac91-4f3e80cde70d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Transformation\n",
    "- get a new df after execution of each transformation operation\n",
    "- lazy evaluation based on DAG\n",
    "- 2 types: narrow, wide (requires shuffling vs not required)\n",
    "- Eg: filter, union\n",
    "\n",
    "# Action\n",
    "- return the data to the driver for display or storage into storage layer\n",
    "- when we want to work with actual data\n",
    "- Eg: count, collect, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ac0a316-d56c-4b90-8954-e4817fe94084",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [(1, \"a\"), (2, \"b\"), (3, \"c\")]\n",
    "df = spark.createDataFrame(data, [\"id\", \"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2659b9ab-cdd7-4240-9ea2-b1ad21f4a35f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# show VS collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1c976e6-d21e-483d-a7fa-bfd3a8d1f1f3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "show vs collect"
    }
   },
   "outputs": [],
   "source": [
    "df.show()\n",
    "\n",
    "# VS\n",
    "\n",
    "data = df.collect()  # Retrieves all rows into a Python list\n",
    "for row in data:\n",
    "    print(row)  # Each row is a PySpark Row object\n",
    "\n",
    "# read using list\n",
    "print(data[0].id, data[0].name)\n",
    "print(data[1][\"id\"], data[1][\"name\"])\n",
    "\n",
    "# Convert each Row object into a dictionary\n",
    "rows_as_dicts = [row.asDict() for row in data]\n",
    "print(\"rows_as_dicts:\", rows_as_dicts)\n",
    "print(rows_as_dicts[0]['id'], rows_as_dicts[0]['name'])\n",
    "\n",
    "# Convert into 1 dictionary\n",
    "data_one_dict = {item[\"id\"]:item[\"name\"] for item in rows_as_dicts}\n",
    "print(\"data_one_dict: \", data_one_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99980ec2-d15d-46dd-85cd-04b72f1839a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7bf1804-ada1-4901-938b-43ec78292e37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField \n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "\n",
    "# Create SparkSession object\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "# Create data\n",
    "data = [\n",
    "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
    " ]\n",
    "\n",
    "# Create schema        \n",
    "schema = StructType([\n",
    "     StructField('name', StructType([\n",
    "        StructField('firstname', StringType(), True),\n",
    "        StructField('middlename', StringType(), True),\n",
    "         StructField('lastname', StringType(), True)\n",
    "     ])),\n",
    "     StructField('languages', ArrayType(StringType()), True),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    " ])\n",
    "\n",
    "# Create dataframe\n",
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a99d3502-7149-489c-872f-fd7ce2277739",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "filter() with Column Condition"
    }
   },
   "outputs": [],
   "source": [
    "df.filter(df.state == \"OH\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f53366ae-4bb8-4126-b40a-fed3077d1249",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Using not equal filter condition"
    }
   },
   "outputs": [],
   "source": [
    "df.filter(df.state != \"OH\").show(truncate=False) \n",
    "\n",
    "df.filter(~(df.state == \"OH\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24f8736e-418e-4b2e-bf49-02a24047a5d4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Using col() Function"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df.filter(F.col(\"state\") == \"OH\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee68b211-3773-46c5-9d6c-15c6a6921b27",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Filtering with SQL Expression"
    }
   },
   "outputs": [],
   "source": [
    "# Using SQL Expression\n",
    "df.filter(\"gender == 'M'\").show()\n",
    "\n",
    "# For not equal\n",
    "df.filter(\"gender != 'M'\").show()\n",
    "df.filter(\"gender <> 'M'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88a9bec3-766a-4f06-bb8c-1a1ef532fc72",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Filter with Multiple Conditions"
    }
   },
   "outputs": [],
   "source": [
    "df.filter( (df.state  == \"OH\") & (df.gender  == \"M\") ).show(truncate=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35b3bccd-c414-4cab-bc60-aca6d705e168",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Filter Based on List Values"
    }
   },
   "outputs": [],
   "source": [
    "li=[\"OH\",\"CA\",\"DE\"]\n",
    "df.filter(df.state.isin(li)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53a1760b-e343-45eb-ba9c-7a2cc9c7d4bc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Filter Based on Starts With, Ends With, Contains"
    }
   },
   "outputs": [],
   "source": [
    "# Using startswith\n",
    "df.filter(df.state.startswith(\"N\")).show()\n",
    "\n",
    "#using endswith\n",
    "df.filter(df.state.endswith(\"H\")).show()\n",
    "\n",
    "#contains\n",
    "df.filter(df.state.contains(\"H\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4d5cbeb-9ea2-44c5-bb38-97d83c3748b3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Filtering with Regular Expression"
    }
   },
   "outputs": [],
   "source": [
    "data2 = [\n",
    "    (2,\"Michael rOse\"),\n",
    "    (3,\"Robert Williams\"),\n",
    "    (4,\"Rames Rose\"),\n",
    "    (5,\"Rames rose\")\n",
    "  ]\n",
    "df2 = spark.createDataFrame(data = data2, schema = [\"id\",\"name\"])\n",
    "\n",
    "# like - SQL LIKE pattern\n",
    "# This check case sensitive\n",
    "df2.filter(df2.name.like(\"%rose%\")).show()\n",
    "\n",
    "# SQL ILIKE expression (case insensitive LIKE). \n",
    "# Returns a boolean Column based on a case insensitive match.\n",
    "df2.filter(df2.name.ilike('%Rose')).show()\n",
    "\n",
    "# rlike - SQL RLIKE pattern (LIKE with Regex)\n",
    "# regular expression (regex) matching\n",
    "# This check case insensitive\n",
    "df2.filter(df2.name.rlike(\"(?i)^*rose$\")).show()\n",
    "\n",
    "# (?i) -> Indicates case insensitivity for the regex matching.\n",
    "# ^ -> matching must occur at the beginning of the string."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "transformation_action",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
