{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fc8b7da-6d83-46c6-b002-ed3090d59a37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "BroadcastVariable \n",
    "- optimizing join operations.\n",
    "- suitable when one side of the datasets in the join is fairly small. (The threshold can be configured using “spark. sql. autoBroadcastJoinThreshold” which is by default 10MB\n",
    "\n",
    "**Explicit Broadcast Join:**\n",
    "\n",
    "Usage: In this type of broadcast join, you explicitly specify which DataFrame should be broadcasted using the broadcast function.\n",
    "\n",
    "Advantage: Gives you fine-grained control over which DataFrame to broadcast.\n",
    "\n",
    "\n",
    "**Auto Broadcast Join:**\n",
    "\n",
    "Usage: In an auto broadcast join, PySpark's optimizer automatically determines whether to use a broadcast join based on the size of the DataFrame and the autoBroadcastJoinThreshold configuration parameter.\n",
    "\n",
    "Advantage: Simplifies the process as the system automatically decides whether to broadcast a DataFrame.\n",
    "\n",
    "![](/Workspace/Users/jif170122@gmail.com/spark/broadcast_join.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bda8628-1cd3-4f84-b52c-a10315701268",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "setting autoBroadcastJoinThreshold in PySpark"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "#Threshold Size:\n",
    "#autoBroadcastJoinThreshold is set to a specific size in bytes. If the estimated size of a DataFrame is below this threshold, PySpark will automatically choose to broadcast it in join operations.\n",
    "\n",
    "spark = SparkSession.builder.appName(\"BroadcastJoinExample\"). \\\n",
    "        config(\"spark.sql.autoBroadcastJoinThreshold\", 50 * 1024 * 1024). \\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61c11e90-e70f-4400-ae60-35167e46aa94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a large DataFrame\n",
    "large_data = [(1, \"A\"), (2, \"B\"), (3, \"C\")]\n",
    "large_df = spark.createDataFrame(large_data, [\"id\", \"value\"])\n",
    "\n",
    "# Create a small DataFrame\n",
    "small_data = [(1, \"Category_1\"), (2, \"Category_2\")]\n",
    "small_df = spark.createDataFrame(small_data, [\"id\", \"category\"])\n",
    "\n",
    "# Perform a broadcast join operation\n",
    "result = large_df.join(broadcast(small_df), \"id\")\n",
    "\n",
    "# When performing a join, PySpark's optimizer estimates the size of each DataFrame involved in the join.\n",
    "#If the size of one DataFrame is below the threshold, it is broadcasted to all worker nodes, reducing the need for data shuffling.\n",
    "\n",
    "\n",
    "# Show the results\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "727116ee-7598-4916-bc02-9fd730733277",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Explicit Broadcast Join"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "spark = SparkSession.builder.appName(\"BroadcastVariablePattern\").getOrCreate()\n",
    "\n",
    "#Create Large and Lookup DataFrames:\n",
    "\n",
    "large_data = [(1, \"A\"), (2, \"B\"), (3, \"C\"), (4, \"D\"), (5, \"E\"), (6, \"F\"),(7,'G'),(8,'H')]\n",
    "large_df = spark.createDataFrame(large_data, [\"id\", \"value\"])\n",
    "\n",
    "lookup_data = [(1, \"Category_1\"), (2, \"Category_2\")]\n",
    "lookup_df = spark.createDataFrame(lookup_data, [\"id\", \"category\"])\n",
    "\n",
    "#Broadcast the Small DataFrame:\n",
    "broadcast_lookup_df = broadcast(lookup_df)\n",
    "\n",
    "\n",
    "#Perform Broadcast Join and Regular Join:\n",
    "result_broadcast_join = large_df.join(broadcast_lookup_df, \"id\")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"BroadcastVariablePattern\").config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\").getOrCreate()\n",
    "result_regular_join = large_df.join(lookup_df, \"id\")\n",
    "\n",
    "#Display Results:\n",
    "\n",
    "print(\"Broadcast Join Result:\")\n",
    "result_broadcast_join.show()\n",
    "\n",
    "\n",
    "print(\"Regular Join Result:\")\n",
    "result_regular_join.show()\n",
    "\n",
    "#Display Execution Plans:\n",
    "\n",
    "print(\"Broadcast Join Execution Plan:\")\n",
    "result_broadcast_join.explain()\n",
    "\n",
    "print(\"Regular Join Execution Plan:\")\n",
    "result_regular_join.explain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a312bed8-2162-4d03-b0b1-4760917b1cc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "broadcast_join",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
